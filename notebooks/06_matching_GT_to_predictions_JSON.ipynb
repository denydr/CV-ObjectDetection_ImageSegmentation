{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f87432d-8de1-4274-aaee-b491505a9c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed GT for sequence 'bike-packing' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/bike-packing_gt.json\n",
      "Saved processed GT for sequence 'skate-park' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/skate-park_gt.json\n",
      "Saved processed GT for sequence 'stroller' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/stroller_gt.json\n",
      "Saved processed GT for sequence 'upside-down' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/upside-down_gt.json\n",
      "Saved processed GT for sequence 'cat-girl' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/cat-girl_gt.json\n",
      "Saved processed GT for sequence 'classic-car' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/classic-car_gt.json\n",
      "Saved processed GT for sequence 'hockey' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/hockey_gt.json\n",
      "Saved processed GT for sequence 'horsejump-high' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/horsejump-high_gt.json\n",
      "Saved processed GT for sequence 'kid-football' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/kid-football_gt.json\n",
      "Saved processed GT for sequence 'mbike-trick' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/mbike-trick_gt.json\n",
      "Saved processed GT for sequence 'pigs' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/pigs_gt.json\n",
      "Saved processed GT for sequence 'motocross-jump' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/motocross-jump_gt.json\n",
      "Saved processed GT for sequence 'paragliding' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/paragliding_gt.json\n",
      "Saved processed GT for sequence 'snowboard' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/snowboard_gt.json\n",
      "Saved processed GT for sequence 'boxing-fisheye' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/boxing-fisheye_gt.json\n",
      "Saved processed GT for sequence 'dancing' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/dancing_gt.json\n",
      "Saved processed GT for sequence 'dogs-jump' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/dogs-jump_gt.json\n",
      "Saved processed GT for sequence 'judo' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/judo_gt.json\n",
      "Saved processed GT for sequence 'lady-running' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/lady-running_gt.json\n",
      "Saved processed GT for sequence 'hike' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/hike_gt.json\n",
      "Saved processed GT for sequence 'mallard-fly' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/mallard-fly_gt.json\n",
      "Saved processed GT for sequence 'cows' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/cows_gt.json\n",
      "Saved processed GT for sequence 'mallard-water' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/mallard-water_gt.json\n",
      "Saved processed GT for sequence 'dog' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/dog_gt.json\n",
      "Saved processed GT for sequence 'lucia' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/lucia_gt.json\n",
      "Saved processed GT for sequence 'parkour' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/parkour_gt.json\n",
      "Saved processed GT for sequence 'goat' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/goat_gt.json\n",
      "Saved processed GT for sequence 'car-roundabout' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/car-roundabout_gt.json\n",
      "Saved processed GT for sequence 'breakdance-flare' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/breakdance-flare_gt.json\n",
      "Saved processed GT for sequence 'drift-straight' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/drift-straight_gt.json\n",
      "Saved processed GT for sequence 'varanus-cage' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/varanus-cage_gt.json\n",
      "Saved processed GT for sequence 'car-turn' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/car-turn_gt.json\n",
      "Saved processed GT for sequence 'car-shadow' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/car-shadow_gt.json\n",
      "Saved processed GT for sequence 'blackswan' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/blackswan_gt.json\n",
      "Saved processed GT for sequence 'elephant' to /Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations/elephant_gt.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Import paths from your config.\n",
    "from config import REP_BBOX_JSON, CANONICAL_MAPPING_PATH\n",
    "\n",
    "def load_gt_annotations():\n",
    "    \"\"\"\n",
    "    Loads the original GT bounding boxes and labels JSON.\n",
    "    \"\"\"\n",
    "    json_path = REP_BBOX_JSON\n",
    "    if not json_path.exists():\n",
    "        raise FileNotFoundError(f\"GT JSON not found: {json_path}\")\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_canonical_mapping():\n",
    "    \"\"\"\n",
    "    Loads the canonical mapping from the specified JSON file.\n",
    "    \"\"\"\n",
    "    mapping_path = CANONICAL_MAPPING_PATH\n",
    "    if not mapping_path.exists():\n",
    "        raise FileNotFoundError(f\"Canonical mapping file not found: {mapping_path}\")\n",
    "    with open(mapping_path, \"r\") as f:\n",
    "        mapping = json.load(f)\n",
    "    return mapping\n",
    "\n",
    "def convert_box(box):\n",
    "    \"\"\"\n",
    "    Converts a GT box from [x, y, w, h] to [x, y, x+w, y+h].\n",
    "    \"\"\"\n",
    "    x, y, w, h = box\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "def preprocess_gt_annotations():\n",
    "    \"\"\"\n",
    "    Processes the original GT JSON by:\n",
    "      1. Removing instance suffixes from textual labels (e.g. \"person_1\" becomes \"person\")\n",
    "      2. Mapping the resulting label to its numeric equivalent using the canonical mapping.\n",
    "      3. Converting GT boxes from [x, y, w, h] to [x, y, x+w, y+h].\n",
    "      4. Restructuring the annotations so that each sequence becomes a flat dictionary\n",
    "         with frame filenames as keys and for each frame a dictionary containing:\n",
    "            - \"labels\": a list of numeric labels\n",
    "            - \"boxes\": a list of bounding boxes (in [x, y, x+w, y+h] format)\n",
    "            - \"mask_files\": a list containing the mask filename (assumed to be the same as the frame name)\n",
    "         \n",
    "    Returns:\n",
    "        processed (dict): A dictionary with keys \"multi_object\" and \"single_object\", each mapping\n",
    "                          sequence names to their processed annotations.\n",
    "    \"\"\"\n",
    "    gt_data = load_gt_annotations()\n",
    "    canonical_mapping = load_canonical_mapping()\n",
    "    \n",
    "    processed = {\"multi_object\": {}, \"single_object\": {}}\n",
    "    \n",
    "    # Process both object types if present.\n",
    "    for obj_type in [\"multi_object\", \"single_object\"]:\n",
    "        if obj_type not in gt_data:\n",
    "            continue\n",
    "        sequences = gt_data[obj_type]\n",
    "        for seq_name, frames in sequences.items():\n",
    "            seq_dict = {}\n",
    "            for frame, ann in frames.items():\n",
    "                labels = []\n",
    "                boxes = []\n",
    "                for raw_label, bbox in ann.items():\n",
    "                    # Remove instance suffix (e.g. \"bicycle_1\" -> \"bicycle\")\n",
    "                    base_label = raw_label.rsplit(\"_\", 1)[0] if \"_\" in raw_label else raw_label\n",
    "                    # Map the textual label to its numeric code using the canonical mapping.\n",
    "                    numeric_label = canonical_mapping.get(base_label, -1)\n",
    "                    labels.append(numeric_label)\n",
    "                    # Convert the GT box from [x, y, w, h] to [x, y, x+w, y+h]\n",
    "                    boxes.append(convert_box(bbox))\n",
    "                # Include mask_files info: assume the mask file has the same name as the frame.\n",
    "                seq_dict[frame] = {\"labels\": labels, \"boxes\": boxes, \"mask_files\": [frame]}\n",
    "            processed[obj_type][seq_name] = seq_dict\n",
    "    return processed\n",
    "\n",
    "def save_processed_gt(processed, output_dir):\n",
    "    \"\"\"\n",
    "    Saves the processed GT annotations as one JSON per sequence.\n",
    "    \n",
    "    Args:\n",
    "        processed (dict): Processed GT annotations organized by object type.\n",
    "        output_dir (str or Path): Directory where the per-sequence JSON files will be saved.\n",
    "                                 Files will be named \"video-sequence-name_gt.json\".\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Iterate over both object types.\n",
    "    for obj_type, sequences in processed.items():\n",
    "        for seq_name, data in sequences.items():\n",
    "            out_filename = f\"{seq_name}_gt.json\"\n",
    "            out_path = output_dir / out_filename\n",
    "            with open(out_path, \"w\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "            print(f\"Saved processed GT for sequence '{seq_name}' to {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the output directory for processed GT annotations.\n",
    "    output_directory = \"/Users/dd/PycharmProjects/CV-ObjectDetection_ImageSegmentation/metrics_artifacts/gt_annotations\"\n",
    "    processed_annotations = preprocess_gt_annotations()\n",
    "    save_processed_gt(processed_annotations, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
